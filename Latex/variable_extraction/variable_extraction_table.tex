\begin{table}[htbp]
    \centering
    \caption{\\\textsc{STAGE II BENCHMARKING RESULTS}}
    \label{tab:variable_extraction}
    \vspace{0.2cm}
    
    \begin{tabular}{l ccc ccc}
    \toprule
    & \multicolumn{3}{c}{\textbf{LLM (Gemini-2.5-Flash-Lite)}} & \multicolumn{3}{c}{\textbf{Student Transcription}} \\
    \cmidrule(lr){2-4} \cmidrule(lr){5-7}
    & Total & Matched$^*$ & Match Rate & Total & Matched$^*$ & Match Rate \\
    \midrule
    Total Cells & 6,890 & 6,550 & 95.07\% & 6,790 & 6,503 & 95.77\% \\
    \midrule
    \multicolumn{7}{l}{\textit{By Variable}} \\
    \midrule
    \quad Patent ID & 1,378 & 1,371 & 99.49\% & 1,358 & 1,329 & 97.86\% \\
    \quad Name & 1,378 & 1,270 & 92.16\% & 1,358 & 1,289 & 94.92\% \\
    \quad Location & 1,378 & 1,259 & 91.36\% & 1,358 & 1,231 & 90.65\% \\
    \quad Title & 1,378 & 1,287 & 93.40\% & 1,358 & 1,316 & 96.91\% \\
    \quad Date & 1,378 & 1,363 & 98.91\% & 1,358 & 1,338 & 98.53\% \\
    \bottomrule
    \end{tabular}
    
    \vspace{0.5em}
    \begin{minipage}{0.52\textwidth}
    \footnotesize
    \textit{Notes:} This table reports variable extraction performance comparing LLM-generated and student-transcribed variables against the variables from the \textit{perfect} benchmarking dataset. Using the benchmarking results in Table \ref{tab:patent_entry_matching}, we retain only those entries with a unique nearest-neighbor match, yielding 1,378 matched entries for the LLM and 1,358 for student transcriptions. For each entry, we extract five variables (patent ID, assignee, location, title, and application date) and compare them with the variable values in the \textit{perfect} benchmarking datasets. Completed entries are excluded from this analysis. $^*$Matches determined using fuzzy string matching with a similarity threshold of 0.9, computed as the ratio of matching characters to total characters using the Levenshtein distance algorithm.
    \end{minipage}
    \end{table}